"""
Azure ML - Weather Forecasting PIPELINE COMPLET
Pr√©diction : Temp√©rature (r√©gression) + Pr√©cipitations (classification)
Pipeline unifi√© avec mod√®les li√©s
Compatible Azure ML - Sans imbalanced-learn
VERSION FINALE - Pipeline int√©gr√© avec D√âTECTION OVERFITTING CORRIG√âE
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from collections import Counter
import os
import json
import pickle

# ML Libraries
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import Ridge, Lasso, LogisticRegression
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, roc_auc_score
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin

# Azure ML et MLflow
import mlflow
import mlflow.sklearn
from mlflow.models.signature import infer_signature
from azure.ai.ml import MLClient
from azure.ai.ml.entities import Model
from azure.identity import DefaultAzureCredential, AzureCliCredential

# Azure Storage
from azure.storage.blob import BlobServiceClient

# Pour charger les variables d'environnement
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()


class DataBalancer:
    """Classe pour le balancing des donn√©es sans imbalanced-learn"""
    
    @staticmethod
    def smote_simple(X, y, k_neighbors=5, random_state=42):
        """
        Impl√©mentation simple de SMOTE (Synthetic Minority Over-sampling Technique)
        Compatible Azure ML sans d√©pendances externes
        """
        np.random.seed(random_state)
        
        # Identifier les classes
        classes, counts = np.unique(y, return_counts=True)
        
        if len(classes) <= 1:
            return X, y
        
        # Trouver la classe majoritaire
        max_count = counts.max()
        
        X_resampled = []
        y_resampled = []
        
        for cls in classes:
            X_cls = X[y == cls]
            
            # Garder toutes les instances de la classe
            X_resampled.append(X_cls)
            y_resampled.extend([cls] * len(X_cls))
            
            # Si classe minoritaire, g√©n√©rer des exemples synth√©tiques
            if len(X_cls) < max_count:
                n_synthetic = max_count - len(X_cls)
                
                for _ in range(n_synthetic):
                    # Choisir un exemple al√©atoire
                    idx = np.random.randint(0, len(X_cls))
                    sample = X_cls[idx]
                    
                    # Trouver k voisins les plus proches (simplifi√©)
                    distances = np.linalg.norm(X_cls - sample, axis=1)
                    k = min(k_neighbors, len(X_cls) - 1)
                    nearest_idx = np.argsort(distances)[1:k+1]
                    
                    # Choisir un voisin al√©atoire
                    neighbor_idx = np.random.choice(nearest_idx)
                    neighbor = X_cls[neighbor_idx]
                    
                    # G√©n√©rer un exemple synth√©tique
                    alpha = np.random.random()
                    synthetic = sample + alpha * (neighbor - sample)
                    
                    X_resampled.append(synthetic.reshape(1, -1))
                    y_resampled.append(cls)
        
        X_balanced = np.vstack(X_resampled)
        y_balanced = np.array(y_resampled)
        
        return X_balanced, y_balanced
    
    @staticmethod
    def random_oversample(X, y, random_state=42):
        """Over-sampling al√©atoire de la classe minoritaire"""
        np.random.seed(random_state)
        
        classes, counts = np.unique(y, return_counts=True)
        
        if len(classes) <= 1:
            return X, y
        
        max_count = counts.max()
        
        X_resampled = []
        y_resampled = []
        
        for cls in classes:
            X_cls = X[y == cls]
            y_cls = y[y == cls]
            
            if len(X_cls) < max_count:
                # Over-sample
                indices = np.random.choice(len(X_cls), max_count, replace=True)
                X_resampled.append(X_cls[indices])
                y_resampled.extend([cls] * max_count)
            else:
                X_resampled.append(X_cls)
                y_resampled.extend(y_cls)
        
        X_balanced = np.vstack(X_resampled)
        y_balanced = np.array(y_resampled)
        
        return X_balanced, y_balanced


class WeatherPredictionPipeline(BaseEstimator, TransformerMixin):
    """
    Pipeline unifi√© pour pr√©diction m√©t√©o
    1. Pr√©dit la temp√©rature
    2. Utilise la temp√©rature pr√©dite pour pr√©dire la pluie
    """
    
    def __init__(self, temp_model=None, rain_model=None, scaler=None):
        self.temp_model = temp_model
        self.rain_model = rain_model
        self.scaler = scaler
        self.temp_feature_names = None
        self.rain_feature_names = None
        
    def fit(self, X_temp, y_temp, X_rain, y_rain):
        """
        Entra√Æner les deux mod√®les
        X_temp: features pour temp√©rature
        y_temp: target temp√©rature
        X_rain: features pour pluie (inclut temp r√©elle)
        y_rain: target pluie (0/1)
        """
        print("üîß Entra√Ænement du pipeline unifi√©...")
        
        # Entra√Æner le mod√®le de temp√©rature
        print("  1Ô∏è‚É£ Entra√Ænement mod√®le temp√©rature...")
        self.temp_model.fit(X_temp, y_temp)
        print("     ‚úì Mod√®le temp√©rature entra√Æn√©")
        
        # Entra√Æner le mod√®le de pluie
        print("  2Ô∏è‚É£ Entra√Ænement mod√®le pluie...")
        self.rain_model.fit(X_rain, y_rain)
        print("     ‚úì Mod√®le pluie entra√Æn√©")
        
        return self
    
    def predict(self, X_temp):
        """
        Pr√©diction compl√®te:
        1. Pr√©dit temp√©rature
        2. Ajoute temp√©rature pr√©dite aux features
        3. Pr√©dit pluie
        """
        # Pr√©dire la temp√©rature
        temp_pred = self.temp_model.predict(X_temp)
        
        # Cr√©er les features pour la pr√©diction de pluie
        # Ajouter la temp√©rature pr√©dite comme nouvelle feature
        X_rain = np.column_stack([X_temp, temp_pred])
        
        # Pr√©dire la pluie
        rain_pred = self.rain_model.predict(X_rain)
        
        return {
            'temperature': temp_pred,
            'will_rain': rain_pred
        }
    
    def predict_proba(self, X_temp):
        """Pr√©diction avec probabilit√©s pour la pluie"""
        # Pr√©dire la temp√©rature
        temp_pred = self.temp_model.predict(X_temp)
        
        # Cr√©er les features pour la pr√©diction de pluie
        X_rain = np.column_stack([X_temp, temp_pred])
        
        # Pr√©dire la pluie avec probabilit√©s
        rain_proba_all = self.rain_model.predict_proba(X_rain)
        
        # G√©rer le cas o√π il n'y a qu'une seule classe
        if rain_proba_all.shape[1] == 1:
            # Une seule classe (probablement 0 - pas de pluie)
            rain_proba = np.zeros(len(X_temp))
            rain_pred = np.zeros(len(X_temp), dtype=int)
        else:
            # Deux classes normales
            rain_proba = rain_proba_all[:, 1]
            rain_pred = (rain_proba > 0.5).astype(int)
        
        return {
            'temperature': temp_pred,
            'will_rain': rain_pred,
            'rain_probability': rain_proba
        }


class WeatherMLPipeline:
    """Pipeline ML complet pour pr√©diction m√©t√©o"""
    
    def __init__(self, storage_account_name, container_name, storage_account_key=None, 
                 experiment_name="weather-forecast", azure_ml_client=None):
        self.storage_account = storage_account_name
        self.container = container_name
        self.storage_account_key = storage_account_key
        self.experiment_name = experiment_name
        self.azure_ml_client = azure_ml_client
        
        # Mod√®les de r√©gression pour temp√©rature
        self.regression_models = {
            'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10),
            'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=5),
            'Ridge': Ridge(alpha=1.0, random_state=42),
            'Lasso': Lasso(alpha=0.1, random_state=42),
            'DecisionTree': DecisionTreeRegressor(max_depth=10, random_state=42)
        }
        
        # Mod√®les de classification pour pluie - ORDRE IMPORTANT (simple ‚Üí complexe)
        self.classification_models = {
            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),
            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10),
            'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42, max_depth=5),
            'DecisionTree': DecisionTreeClassifier(max_depth=10, random_state=42)
        }
        
        self.best_temp_model = None
        self.best_temp_model_name = None
        self.best_temp_score = float('-inf')
        self.best_temp_metrics = {}
        
        self.best_rain_model = None
        self.best_rain_model_name = None
        self.best_rain_score = float('-inf')
        self.best_rain_metrics = {}
        
        self.unified_pipeline = None
        self.scaler = StandardScaler()
        self.balancer = DataBalancer()
        
        # Flag pour indiquer si le mod√®le de pluie est disponible
        self.rain_model_available = False
        
    def load_data_from_blob(self, blob_path="bronze/history"):
        """Charger les donn√©es depuis Azure Blob Storage avec cl√© d'acc√®s"""
        try:
            print(f"  üîó Connexion au Storage Account: {self.storage_account}")
            print(f"  üì¶ Container: {self.container}")
            print(f"  üìÇ Path: {blob_path}")
            
            # Connexion au blob storage avec cl√© d'acc√®s
            account_url = f"https://{self.storage_account}.blob.core.windows.net"
            
            if self.storage_account_key:
                blob_service_client = BlobServiceClient(
                    account_url=account_url, 
                    credential=self.storage_account_key
                )
                print("  üîë Authentification avec cl√© d'acc√®s")
            else:
                print("  ‚ö†Ô∏è Pas de cl√© fournie, tentative acc√®s public")
                blob_service_client = BlobServiceClient(account_url=account_url)
            
            container_client = blob_service_client.get_container_client(self.container)
            
            # Lister les blobs
            print(f"  üìã Liste des fichiers dans {blob_path}...")
            blobs = list(container_client.list_blobs(name_starts_with=blob_path))
            print(f"  ‚úì {len(blobs)} fichiers trouv√©s")
            
            all_data = []
            blob_count = 0
            
            for blob in blobs:
                if blob.name.endswith('.json'):
                    blob_count += 1
                    print(f"  üìÑ Lecture: {blob.name}")
                    blob_client = container_client.get_blob_client(blob.name)
                    content = blob_client.download_blob().readall().decode('utf-8-sig')
                    
                    # Lire ligne par ligne (format JSONL)
                    for line in content.strip().split('\n'):
                        if line:
                            try:
                                all_data.append(json.loads(line))
                            except json.JSONDecodeError as e:
                                print(f"    ‚ö†Ô∏è Erreur JSON sur ligne: {e}")
                                continue
            
            if not all_data:
                print(f"  ‚ö†Ô∏è Aucune donn√©e JSON trouv√©e dans {blob_path}")
                return None
            
            df = pd.DataFrame(all_data)
            print(f"  ‚úì {blob_count} fichiers JSON lus")
            print(f"  ‚úì {len(df)} observations charg√©es")
            print(f"  ‚úì Colonnes: {list(df.columns)[:10]}")
            
            return df
            
        except Exception as e:
            print(f"  ‚úó Erreur lors du chargement: {e}")
            return None
    
    def feature_engineering(self, df):
        """Cr√©er des features pour la pr√©diction horaire"""
        print("  üîß Feature engineering en cours...")
        df = df.copy()
        
        # Convertir les timestamps
        df['observation_time'] = pd.to_datetime(df['observation_time'])
        df['ingestion_timestamp'] = pd.to_datetime(df['ingestion_timestamp'])
        
        # Features temporelles
        df['hour'] = df['observation_time'].dt.hour
        df['day_of_week'] = df['observation_time'].dt.dayofweek
        df['month'] = df['observation_time'].dt.month
        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        
        # Features cycliques pour l'heure
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        
        # Features d'interaction
        df['temp_humidity_interaction'] = df['temp_c'] * df['humidity'] / 100
        df['wind_temp_interaction'] = df['wind_kph'] * df['temp_c']
        
        # Encoder les variables cat√©gorielles
        le_city = LabelEncoder()
        le_condition = LabelEncoder()
        
        df['city_encoded'] = le_city.fit_transform(df['city'])
        df['condition_encoded'] = le_condition.fit_transform(df['condition'])
        
        # Sauvegarder les encoders
        self.city_encoder = le_city
        self.condition_encoder = le_condition
        
        # Features de lag
        df = df.sort_values(['city', 'observation_time'])
        
        for lag in [1, 2, 3]:
            df[f'temp_lag_{lag}'] = df.groupby('city')['temp_c'].shift(lag)
            df[f'precip_lag_{lag}'] = df.groupby('city')['precip_mm'].shift(lag)
        
        lag_cols = [col for col in df.columns if 'lag' in col]
        df[lag_cols] = df[lag_cols].fillna(df[lag_cols].mean())
        
        print(f"  ‚úì {len(df.columns)} features cr√©√©es")
        
        return df
    
    def prepare_features_target(self, df, target='temp_c'):
        """Pr√©parer les features et la cible"""
        feature_cols = [
            'hour', 'day_of_week', 'month', 'is_weekend',
            'hour_sin', 'hour_cos',
            'city_encoded', 'condition_encoded',
            'is_day', 'wind_kph', 'wind_degree', 'pressure_mb',
            'humidity', 'cloud_cover', 'uv_index', 'vis_km',
            'temp_humidity_interaction', 'wind_temp_interaction'
        ]
        
        lag_cols = [col for col in df.columns if 'lag' in col]
        feature_cols.extend(lag_cols)
        
        feature_cols = [col for col in feature_cols if col in df.columns]
        
        X = df[feature_cols].copy()
        y = df[target].copy()
        
        mask = ~(X.isnull().any(axis=1) | y.isnull())
        X = X[mask]
        y = y[mask]
        
        print(f"  ‚úì Features finales: {len(feature_cols)}")
        print(f"  ‚úì Observations valides: {len(X)}")
        
        return X, y, feature_cols
    
    def create_classification_target(self, df, target_col='precip_mm', threshold=0.1):
        """Cr√©er une cible de classification pour les pr√©cipitations"""
        df = df.copy()
        df['will_rain'] = (df[target_col] > threshold).astype(int)
        return df
    
    def analyze_data_balance(self, y, task='regression'):
        """Analyser l'√©quilibre des donn√©es"""
        if task == 'classification':
            balance = Counter(y)
            print("\nüìä Distribution des classes:")
            for cls, count in sorted(balance.items()):
                print(f"  Classe {cls}: {count} ({count/len(y)*100:.1f}%)")
            
            ratio = max(balance.values()) / min(balance.values()) if min(balance.values()) > 0 else 1
            print(f"\n‚öñÔ∏è Ratio d√©s√©quilibre: {ratio:.2f}:1")
            
            if ratio > 5:
                print("  ‚Üí SMOTE recommand√© (fort d√©s√©quilibre)")
                return 'smote'
            elif ratio > 3:
                print("  ‚Üí Over-sampling recommand√© (d√©s√©quilibre mod√©r√©)")
                return 'oversample'
            elif ratio > 1.5:
                print("  ‚Üí Over-sampling recommand√© (l√©ger d√©s√©quilibre)")
                return 'oversample'
            else:
                print("  ‚Üí Pas de balancing n√©cessaire")
                return 'none'
        else:
            print("\nüìä Distribution de la cible (r√©gression):")
            print(f"  Min: {y.min():.2f}")
            print(f"  Max: {y.max():.2f}")
            print(f"  Mean: {y.mean():.2f}")
            print(f"  Std: {y.std():.2f}")
            return 'none'
    
    def balance_data(self, X, y, strategy='smote'):
        """Appliquer le balancing des donn√©es"""
        if strategy == 'none':
            return X, y
        
        print(f"\nüîÑ Application du balancing: {strategy}")
        print(f"  Avant: {len(X)} √©chantillons")
        
        X_array = X.values if isinstance(X, pd.DataFrame) else X
        y_array = y.values if isinstance(y, pd.Series) else y
        
        if strategy == 'smote':
            X_balanced, y_balanced = DataBalancer.smote_simple(X_array, y_array)
        elif strategy == 'oversample':
            X_balanced, y_balanced = DataBalancer.random_oversample(X_array, y_array)
        else:
            X_balanced, y_balanced = X_array, y_array
        
        print(f"  Apr√®s: {len(X_balanced)} √©chantillons")
        
        balance = Counter(y_balanced)
        print(f"\n  Nouvelle distribution:")
        for cls, count in sorted(balance.items()):
            print(f"    Classe {cls}: {count} ({count/len(y_balanced)*100:.1f}%)")
        
        return X_balanced, y_balanced
    
    def train_temperature_models(self, X_train, X_test, y_train, y_test):
        """Entra√Æner et comparer les mod√®les de temp√©rature"""
        results = {}
        
        print("\n" + "="*80)
        print("üå°Ô∏è  ENTRA√éNEMENT DES MOD√àLES DE TEMP√âRATURE")
        print("="*80)
        
        for model_name, model in self.regression_models.items():
            print(f"\nüì¶ Entra√Ænement: {model_name}")
            
            model.fit(X_train, y_train)
            
            y_pred_train = model.predict(X_train)
            y_pred_test = model.predict(X_test)
            
            mae_train = mean_absolute_error(y_train, y_pred_train)
            mae_test = mean_absolute_error(y_test, y_pred_test)
            rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
            rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
            r2_train = r2_score(y_train, y_pred_train)
            r2_test = r2_score(y_test, y_pred_test)
            
            cv_folds = min(5, len(X_train))
            if cv_folds >= 2:
                cv_scores = cross_val_score(model, X_train, y_train, cv=cv_folds, 
                                           scoring='neg_mean_absolute_error')
                cv_mae = -cv_scores.mean()
            else:
                cv_mae = mae_test
            
            results[model_name] = {
                'model': model,
                'mae_train': mae_train,
                'mae_test': mae_test,
                'rmse_train': rmse_train,
                'rmse_test': rmse_test,
                'r2_train': r2_train,
                'r2_test': r2_test,
                'cv_mae': cv_mae
            }
            
            print(f"  ‚úì MAE Test: {mae_test:.3f}¬∞C")
            print(f"  ‚úì RMSE Test: {rmse_test:.3f}¬∞C")
            print(f"  ‚úì R¬≤ Test: {r2_test:.3f}")
            
            if r2_test > self.best_temp_score:
                self.best_temp_score = r2_test
                self.best_temp_model = model
                self.best_temp_model_name = model_name
                self.best_temp_metrics = {
                    'mae_train': mae_train,
                    'mae_test': mae_test,
                    'rmse_train': rmse_train,
                    'rmse_test': rmse_test,
                    'r2_train': r2_train,
                    'r2_test': r2_test,
                    'cv_mae': cv_mae
                }
        
        return results
    
    def train_rain_models(self, X_train, X_test, y_train, y_test):
        """
        Entra√Æner et comparer les mod√®les de pluie
        AVEC D√âTECTION D'OVERFITTING AM√âLIOR√âE - P√©nalise les scores parfaits
        """
        results = {}
        
        print("\n" + "="*80)
        print("üåßÔ∏è  ENTRA√éNEMENT DES MOD√àLES DE PLUIE (d√©tection overfitting renforc√©e)")
        print("="*80)
        
        # V√©rifier si on a au moins 2 classes
        n_classes = len(np.unique(y_train))
        if n_classes < 2:
            print(f"\n‚ö†Ô∏è ATTENTION: Une seule classe d√©tect√©e dans les donn√©es d'entra√Ænement!")
            print(f"   Impossible d'entra√Æner des mod√®les de classification binaire.")
            print(f"   Classes pr√©sentes: {np.unique(y_train)}")
            return results
        
        # D√©terminer le nombre de folds pour CV
        min_class_count = min(Counter(y_train).values())
        cv_folds = min(3, min_class_count)
        
        if cv_folds < 2:
            print(f"\n‚ö†Ô∏è ATTENTION: Pas assez de donn√©es pour Cross-Validation fiable")
            print(f"   Classe minoritaire: {min_class_count} √©chantillons")
            print(f"   Un dataset plus large est fortement recommand√©!")
        
        # üîë D√©tecter si le dataset est trop petit
        dataset_too_small = len(X_train) < 100 or len(X_test) < 20
        if dataset_too_small:
            print(f"\n‚ö†Ô∏è DATASET TROP PETIT D√âTECT√â:")
            print(f"   Train: {len(X_train)} | Test: {len(X_test)}")
            print(f"   ‚Üí P√©nalit√©s automatiques pour scores parfaits activ√©es")
        
        for model_name, model in self.classification_models.items():
            print(f"\nüì¶ Entra√Ænement: {model_name}")
            
            # Entra√Ænement
            model.fit(X_train, y_train)
            
            # Pr√©dictions
            y_pred_train = model.predict(X_train)
            y_pred_test = model.predict(X_test)
            
            # M√©triques sur train
            acc_train = accuracy_score(y_train, y_pred_train)
            
            # M√©triques sur test
            acc_test = accuracy_score(y_test, y_pred_test)
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_test, y_pred_test, average='binary', zero_division=0
            )
            
            # ROC AUC si le mod√®le supporte predict_proba
            roc_auc = 0.0
            if hasattr(model, 'predict_proba'):
                try:
                    y_proba_all = model.predict_proba(X_test)
                    if y_proba_all.shape[1] == 2:
                        y_proba = y_proba_all[:, 1]
                        if len(np.unique(y_test)) > 1:
                            roc_auc = roc_auc_score(y_test, y_proba)
                except Exception as e:
                    print(f"    ‚ö†Ô∏è Erreur calcul ROC AUC: {e}")
                    roc_auc = 0.0
            
            # üîë CROSS-VALIDATION pour d√©tecter l'overfitting
            cv_f1_mean = 0.0
            cv_f1_std = 0.0
            overfitting_detected = False
            final_score = f1  # Score par d√©faut
            
            if cv_folds >= 2 and len(X_train) >= 10:
                try:
                    print(f"  üìä Cross-Validation ({cv_folds}-fold)...")
                    cv_scores = cross_val_score(
                        model, X_train, y_train, 
                        cv=cv_folds,
                        scoring='f1'
                    )
                    cv_f1_mean = cv_scores.mean()
                    cv_f1_std = cv_scores.std()
                    
                    print(f"     CV F1: {cv_f1_mean:.3f} (¬±{cv_f1_std:.3f})")
                    
                    # üî¥ NOUVELLE LOGIQUE DE D√âTECTION - P√©nalise TOUJOURS les scores parfaits
                    
                    # 1. Scores quasi-parfaits sur petit dataset = TR√àS SUSPECT
                    if f1 >= 0.95 and acc_test >= 0.95 and dataset_too_small:
                        print(f"  ‚ö†Ô∏è  OVERFITTING TR√àS PROBABLE!")
                        print(f"     Scores quasi-parfaits (F1={f1:.3f}, Acc={acc_test:.3f}) sur petit dataset")
                        overfitting_detected = True
                        
                        # P√©nalit√© s√©v√®re si les deux sont parfaits
                        if f1 == 1.0 and cv_f1_mean >= 0.95:
                            final_score = 0.5  # P√©nalit√© maximum
                            print(f"     ‚Üí P√©nalit√© s√©v√®re (scores parfaits): {final_score:.3f}")
                        else:
                            final_score = cv_f1_mean * 0.7  # P√©nalit√© mod√©r√©e
                            print(f"     ‚Üí P√©nalit√© mod√©r√©e: {final_score:.3f}")
                    
                    # 2. Grand √©cart Test vs CV (ind√©pendamment des scores)
                    elif abs(f1 - cv_f1_mean) > 0.25:  # Seuil abaiss√© √† 25%
                        print(f"  ‚ö†Ô∏è  OVERFITTING D√âTECT√â!")
                        print(f"     √âcart Test F1 ({f1:.3f}) vs CV F1 ({cv_f1_mean:.3f}) = {abs(f1 - cv_f1_mean):.3f}")
                        overfitting_detected = True
                        final_score = cv_f1_mean  # Utiliser CV
                    
                    # 3. Bon √©quilibre mais sur petit dataset
                    elif dataset_too_small:
                        print(f"  ‚úì  √âquilibre Train/CV/Test acceptable")
                        # L√©g√®re p√©nalit√© pour petit dataset
                        final_score = f1 * 0.9
                        print(f"     Petit dataset ‚Üí l√©g√®re p√©nalit√©: {final_score:.3f}")
                    
                    # 4. Tout va bien
                    else:
                        print(f"  ‚úÖ Bon √©quilibre - Dataset suffisant")
                        final_score = f1
                        
                except Exception as e:
                    print(f"    ‚ö†Ô∏è Erreur Cross-Validation: {e}")
                    # Si CV √©choue mais score parfait
                    if f1 >= 0.95 and acc_test >= 0.95 and dataset_too_small:
                        print(f"  ‚ö†Ô∏è  Score quasi-parfait + CV √©chec ‚Üí P√©nalit√© s√©v√®re")
                        final_score = f1 * 0.5
                        overfitting_detected = True
                    else:
                        final_score = f1
            else:
                print(f"  ‚ö†Ô∏è  Dataset trop petit pour CV fiable ({len(X_train)} √©chantillons)")
                # P√©nalit√© automatique bas√©e sur la taille et les scores
                if f1 >= 0.95:
                    final_score = f1 * 0.5  # P√©nalit√© s√©v√®re
                    print(f"     Score quasi-parfait + mini-dataset ‚Üí P√©nalit√© s√©v√®re: {final_score:.3f}")
                    overfitting_detected = True
                elif len(X_train) < 30:
                    final_score = f1 * 0.6  # P√©nalit√© forte
                    print(f"     P√©nalit√© forte appliqu√©e: {final_score:.3f}")
                    overfitting_detected = True
                else:
                    final_score = f1 * 0.8  # P√©nalit√© mod√©r√©e
                    print(f"     P√©nalit√© mod√©r√©e appliqu√©e: {final_score:.3f}")
            
            # Stocker les r√©sultats
            results[model_name] = {
                'model': model,
                'acc_train': acc_train,
                'acc_test': acc_test,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'roc_auc': roc_auc,
                'cv_f1_mean': cv_f1_mean,
                'cv_f1_std': cv_f1_std,
                'final_score': final_score,
                'overfitting_detected': overfitting_detected
            }
            
            # Affichage des m√©triques
            print(f"  ‚úì Accuracy Train: {acc_train:.3f}")
            print(f"  ‚úì Accuracy Test: {acc_test:.3f}")
            print(f"  ‚úì Precision: {precision:.3f}")
            print(f"  ‚úì Recall: {recall:.3f}")
            print(f"  ‚úì F1-Score Test: {f1:.3f}")
            if cv_f1_mean > 0:
                print(f"  ‚úì F1-Score CV: {cv_f1_mean:.3f} (¬±{cv_f1_std:.3f})")
            if roc_auc > 0:
                print(f"  ‚úì ROC AUC: {roc_auc:.3f}")
            print(f"  üéØ Score Final (s√©lection): {final_score:.3f}")
            
            if overfitting_detected:
                print(f"  ‚ö†Ô∏è  Mod√®le suspect d'overfitting")
            
            # S√©lection bas√©e sur le score final
            if final_score > self.best_rain_score:
                self.best_rain_score = final_score
                self.best_rain_model = model
                self.best_rain_model_name = model_name
                self.best_rain_metrics = {
                    'acc_train': acc_train,
                    'acc_test': acc_test,
                    'precision': precision,
                    'recall': recall,
                    'f1': f1,
                    'roc_auc': roc_auc,
                    'cv_f1_mean': cv_f1_mean,
                    'cv_f1_std': cv_f1_std,
                    'final_score': final_score,
                    'overfitting_detected': overfitting_detected
                }
                print(f"  üèÜ Nouveau meilleur mod√®le! (Score: {final_score:.3f})")
        
        return results
    
    def create_unified_pipeline(self):
        """Cr√©er le pipeline unifi√© avec les meilleurs mod√®les"""
        print("\n" + "="*80)
        print("üîó CR√âATION DU PIPELINE UNIFI√â")
        print("="*80)
        
        self.unified_pipeline = WeatherPredictionPipeline(
            temp_model=self.best_temp_model,
            rain_model=self.best_rain_model,
            scaler=self.scaler
        )
        
        overfitting_warning = ""
        if self.best_rain_metrics.get('overfitting_detected', False):
            overfitting_warning = " ‚ö†Ô∏è (overfitting d√©tect√©)"
        
        print(f"\n‚úÖ Pipeline cr√©√©:")
        print(f"  ‚Ä¢ Mod√®le temp√©rature: {self.best_temp_model_name} (R¬≤={self.best_temp_score:.3f})")
        print(f"  ‚Ä¢ Mod√®le pluie: {self.best_rain_model_name} (Score={self.best_rain_score:.3f}){overfitting_warning}")
        
        return self.unified_pipeline
    
    def log_unified_pipeline_azure(self, run, X_temp_sample, feature_names_temp, feature_names_rain):
        """Enregistrer le pipeline unifi√© dans Azure ML"""
        if self.unified_pipeline is None:
            print("‚ö†Ô∏è Aucun pipeline unifi√© √† enregistrer")
            return
        
        print("\n" + "="*80)
        print("üíæ ENREGISTREMENT DU PIPELINE UNIFI√â DANS AZURE ML")
        print("="*80)
        
        # Log des m√©triques du mod√®le temp√©rature
        print("\nüìä M√©triques - Mod√®le Temp√©rature:")
        for metric, value in self.best_temp_metrics.items():
            mlflow.log_metric(f"temp_{metric}", value)
            print(f"  ‚Ä¢ {metric}: {value:.4f}")
        
        # Log des m√©triques du mod√®le pluie
        print("\nüìä M√©triques - Mod√®le Pluie:")
        for metric, value in self.best_rain_metrics.items():
            if isinstance(value, (int, float, bool)):
                mlflow.log_metric(f"rain_{metric}", float(value))
                print(f"  ‚Ä¢ {metric}: {value:.4f}" if isinstance(value, float) else f"  ‚Ä¢ {metric}: {value}")
        
        # Log des param√®tres
        mlflow.log_param("temp_model_name", self.best_temp_model_name)
        mlflow.log_param("rain_model_name", self.best_rain_model_name)
        mlflow.log_param("n_features_temp", len(feature_names_temp))
        mlflow.log_param("n_features_rain", len(feature_names_rain))
        mlflow.log_param("pipeline_type", "unified")
        mlflow.log_param("rain_model_available", True)
        mlflow.log_param("overfitting_detected", self.best_rain_metrics.get('overfitting_detected', False))
        
        # Log des tags
        mlflow.set_tags({
            "temp_model": self.best_temp_model_name,
            "rain_model": self.best_rain_model_name,
            "model_type": "unified",
            "best_temp_r2": str(self.best_temp_score),
            "best_rain_score": str(self.best_rain_score),
            "overfitting_warning": str(self.best_rain_metrics.get('overfitting_detected', False))
        })
        
        print("\nüì¶ Sauvegarde des mod√®les...")
        
        # Cr√©er un r√©pertoire temporaire
        import tempfile
        import shutil
        temp_dir = tempfile.mkdtemp()
        
        try:
            # Sauvegarder le pipeline unifi√© avec pickle
            print("  üîÑ Pipeline unifi√©...")
            pipeline_path = os.path.join(temp_dir, "unified_pipeline.pkl")
            with open(pipeline_path, 'wb') as f:
                pickle.dump(self.unified_pipeline, f)
            mlflow.log_artifact(pipeline_path, artifact_path="models")
            print("  ‚úì Pipeline unifi√© enregistr√©")
            
            # Sauvegarder le mod√®le de temp√©rature
            print("  üîÑ Mod√®le temp√©rature...")
            temp_model_path = os.path.join(temp_dir, "temperature_model.pkl")
            with open(temp_model_path, 'wb') as f:
                pickle.dump(self.best_temp_model, f)
            mlflow.log_artifact(temp_model_path, artifact_path="models")
            print("  ‚úì Mod√®le temp√©rature enregistr√©")
            
            # Sauvegarder le mod√®le de pluie
            print("  üîÑ Mod√®le pluie...")
            rain_model_path = os.path.join(temp_dir, "rain_model.pkl")
            with open(rain_model_path, 'wb') as f:
                pickle.dump(self.best_rain_model, f)
            mlflow.log_artifact(rain_model_path, artifact_path="models")
            print("  ‚úì Mod√®le pluie enregistr√©")
            
            # Sauvegarder le scaler
            print("  üîÑ Scaler...")
            scaler_path = os.path.join(temp_dir, "scaler.pkl")
            with open(scaler_path, 'wb') as f:
                pickle.dump(self.scaler, f)
            mlflow.log_artifact(scaler_path, artifact_path="models")
            print("  ‚úì Scaler enregistr√©")
            
            # Sauvegarder les encoders
            print("  üîÑ Encoders...")
            encoders_path = os.path.join(temp_dir, "encoders.pkl")
            with open(encoders_path, 'wb') as f:
                pickle.dump({
                    'city_encoder': self.city_encoder,
                    'condition_encoder': self.condition_encoder
                }, f)
            mlflow.log_artifact(encoders_path, artifact_path="models")
            print("  ‚úì Encoders enregistr√©s")
            
            # Sauvegarder les noms de features
            print("  üîÑ Feature names...")
            features_path = os.path.join(temp_dir, "feature_names.json")
            with open(features_path, 'w') as f:
                json.dump({
                    'temp_features': feature_names_temp,
                    'rain_features': feature_names_rain
                }, f)
            mlflow.log_artifact(features_path, artifact_path="models")
            print("  ‚úì Feature names enregistr√©s")
            
            # Sauvegarder un fichier README
            print("  üîÑ Documentation...")
            readme_path = os.path.join(temp_dir, "README.md")
            
            overfitting_note = ""
            if self.best_rain_metrics.get('overfitting_detected', False):
                overfitting_note = f"""
## ‚ö†Ô∏è AVERTISSEMENT OVERFITTING
Le mod√®le de pluie ({self.best_rain_model_name}) a √©t√© d√©tect√© comme potentiellement overfitt√©.
- F1 Test: {self.best_rain_metrics['f1']:.4f}
- F1 CV: {self.best_rain_metrics.get('cv_f1_mean', 0):.4f}
- Score Final (p√©nalis√©): {self.best_rain_score:.4f}

**Recommandations:**
- Collecter plus de donn√©es (minimum 100 cas de pluie)
- R√©√©valuer le mod√®le sur de nouvelles donn√©es
- Consid√©rer une approche plus simple ou r√©gression continue
"""
            
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(f"""# Weather Forecasting Model

## Mod√®les
- **Temp√©rature**: {self.best_temp_model_name} (R¬≤ = {self.best_temp_score:.4f})
- **Pluie**: {self.best_rain_model_name} (Score Final = {self.best_rain_score:.4f})

{overfitting_note}

## M√©triques Pluie
- Accuracy Test: {self.best_rain_metrics.get('acc_test', 0):.4f}
- Precision: {self.best_rain_metrics.get('precision', 0):.4f}
- Recall: {self.best_rain_metrics.get('recall', 0):.4f}
- F1-Score Test: {self.best_rain_metrics.get('f1', 0):.4f}
- F1-Score CV: {self.best_rain_metrics.get('cv_f1_mean', 0):.4f} (¬±{self.best_rain_metrics.get('cv_f1_std', 0):.4f})
- ROC AUC: {self.best_rain_metrics.get('roc_auc', 0):.4f}

## Fichiers
- `unified_pipeline.pkl`: Pipeline complet (temp√©rature + pluie)
- `temperature_model.pkl`: Mod√®le temp√©rature seul
- `rain_model.pkl`: Mod√®le pluie seul
- `scaler.pkl`: StandardScaler pour normalisation
- `encoders.pkl`: LabelEncoders pour city et condition
- `feature_names.json`: Noms des features

## Utilisation
```python
import pickle
import numpy as np

# Charger le pipeline
with open('unified_pipeline.pkl', 'rb') as f:
    pipeline = pickle.load(f)

# Pr√©diction
X = np.array([[...]])  # {len(feature_names_temp)} features
predictions = pipeline.predict_proba(X)

print(predictions['temperature'])
print(predictions['will_rain'])
print(predictions['rain_probability'])
```

## Features ({len(feature_names_temp)})
{', '.join(feature_names_temp[:10])}...
""")
            mlflow.log_artifact(readme_path, artifact_path="models")
            print("  ‚úì Documentation enregistr√©e")
            
        finally:
            # Nettoyer
            shutil.rmtree(temp_dir, ignore_errors=True)
        
        print(f"\n‚úÖ Pipeline unifi√© enregistr√© avec succ√®s dans Azure ML!")
        print(f"   Run ID: {mlflow.active_run().info.run_id}")
        print(f"   Tous les mod√®les sont dans: Artifacts ‚Üí models/")
        
        if self.best_rain_metrics.get('overfitting_detected', False):
            print(f"\n‚ö†Ô∏è  ATTENTION: Overfitting d√©tect√© sur le mod√®le de pluie")
            print(f"   Consultez le README.md pour plus de d√©tails")
    
    def log_temperature_only_azure(self, run, feature_names_temp):
        """Enregistrer uniquement le mod√®le de temp√©rature dans Azure ML"""
        print("\n" + "="*80)
        print("üíæ ENREGISTREMENT DU MOD√àLE TEMP√âRATURE DANS AZURE ML")
        print("="*80)
        
        # Log des m√©triques
        print("\nüìä M√©triques - Mod√®le Temp√©rature:")
        for metric, value in self.best_temp_metrics.items():
            mlflow.log_metric(f"temp_{metric}", value)
            print(f"  ‚Ä¢ {metric}: {value:.4f}")
        
        # Log des param√®tres
        mlflow.log_param("temp_model_name", self.best_temp_model_name)
        mlflow.log_param("n_features_temp", len(feature_names_temp))
        mlflow.log_param("pipeline_type", "temperature_only")
        mlflow.log_param("rain_model_available", False)
        
        # Log des tags
        mlflow.set_tags({
            "temp_model": self.best_temp_model_name,
            "model_type": "temperature_only",
            "best_temp_r2": str(self.best_temp_score)
        })
        
        print("\nüì¶ Enregistrement du mod√®le dans MLflow...")
        
        # Enregistrer le mod√®le de temp√©rature
        print("  üîÑ Mod√®le temp√©rature...")
        mlflow.sklearn.log_model(
            sk_model=self.best_temp_model,
            artifact_path="temperature_model"
        )
        print("  ‚úì Mod√®le temp√©rature enregistr√©")
        
        # Enregistrer le scaler
        print("  üîÑ Scaler...")
        mlflow.sklearn.log_model(
            sk_model=self.scaler,
            artifact_path="scaler"
        )
        print("  ‚úì Scaler enregistr√©")
        
        # Enregistrer les encoders
        print("  üîÑ Encoders...")
        import tempfile
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.pkl')
        try:
            with open(temp_file.name, 'wb') as f:
                pickle.dump({
                    'city_encoder': self.city_encoder,
                    'condition_encoder': self.condition_encoder
                }, f)
            mlflow.log_artifact(temp_file.name, artifact_path="encoders")
            print("  ‚úì Encoders enregistr√©s")
        finally:
            os.unlink(temp_file.name)
        
        print(f"\n‚úÖ Mod√®le temp√©rature enregistr√© avec succ√®s dans Azure ML!")
        print(f"   Run ID: {mlflow.active_run().info.run_id}")

    def display_comparison(self, temp_results, rain_results):
        """Afficher la comparaison des mod√®les"""
        print("\n" + "="*80)
        print("üìä COMPARAISON DES MOD√àLES")
        print("="*80)
        
        print("\nüå°Ô∏è  TEMP√âRATURE (R√©gression):")
        temp_df = pd.DataFrame({
            'Model': list(temp_results.keys()),
            'MAE (¬∞C)': [r['mae_test'] for r in temp_results.values()],
            'RMSE (¬∞C)': [r['rmse_test'] for r in temp_results.values()],
            'R¬≤': [r['r2_test'] for r in temp_results.values()]
        })
        temp_df = temp_df.sort_values('R¬≤', ascending=False)
        temp_df['Best'] = temp_df['Model'].apply(
            lambda x: 'üèÜ' if x == self.best_temp_model_name else ''
        )
        print(temp_df.to_string(index=False))
        
        if rain_results:
            print("\nüåßÔ∏è  PLUIE (Classification avec d√©tection overfitting):")
            rain_df = pd.DataFrame({
                'Model': list(rain_results.keys()),
                'Accuracy': [r['acc_test'] for r in rain_results.values()],
                'Precision': [r['precision'] for r in rain_results.values()],
                'Recall': [r['recall'] for r in rain_results.values()],
                'F1-Test': [r['f1'] for r in rain_results.values()],
                'F1-CV': [r['cv_f1_mean'] if r['cv_f1_mean'] > 0 else float('nan') for r in rain_results.values()],
                'Score Final': [r['final_score'] for r in rain_results.values()],
                'Overfit?': ['‚ö†Ô∏è' if r['overfitting_detected'] else '‚úì' for r in rain_results.values()]
            })
            rain_df = rain_df.sort_values('Score Final', ascending=False)
            rain_df['Best'] = rain_df['Model'].apply(
                lambda x: 'üèÜ' if x == self.best_rain_model_name else ''
            )
            print(rain_df.to_string(index=False))
        else:
            rain_df = None
        
        print(f"\nüèÜ MEILLEURS MOD√àLES S√âLECTIONN√âS:")
        print(f"  ‚Ä¢ Temp√©rature: {self.best_temp_model_name} (R¬≤={self.best_temp_score:.3f})")
        if self.best_rain_model_name:
            overfitting_note = " ‚ö†Ô∏è (overfitting d√©tect√©)" if self.best_rain_metrics.get('overfitting_detected', False) else ""
            print(f"  ‚Ä¢ Pluie: {self.best_rain_model_name} (Score={self.best_rain_score:.3f}){overfitting_note}")
        
        return temp_df, rain_df


def main():
    """Pipeline principal d'entra√Ænement"""
    
    # Configuration Azure
    STORAGE_ACCOUNT = os.getenv("STORAGE_ACCOUNT_NAME", "stweatherwassimv2")
    CONTAINER = os.getenv("CONTAINER_NAME", "weather-data")
    STORAGE_KEY = os.getenv("STORAGE_ACCOUNT_KEY")
    
    SUBSCRIPTION_ID = os.getenv("AZURE_SUBSCRIPTION_ID")
    RESOURCE_GROUP = os.getenv("AZURE_RESOURCE_GROUP")
    WORKSPACE_NAME = os.getenv("AZURE_WORKSPACE_NAME")
    
    if not STORAGE_KEY:
        raise ValueError(
            "‚ö†Ô∏è AZURE_STORAGE_KEY non trouv√©e dans les variables d'environnement.\n"
            "   Ajoutez-la dans votre fichier .env"
        )
    
    print("="*80)
    print("üå§Ô∏è  WEATHER FORECASTING - PIPELINE UNIFI√â AVEC D√âTECTION OVERFITTING")
    print("="*80)
    print("üìã Pr√©dictions:")
    print("  1Ô∏è‚É£ Temp√©rature (R√©gression)")
    print("  2Ô∏è‚É£ Pluie (Classification avec temp√©rature pr√©dite)")
    print("  üîç D√©tection automatique d'overfitting via Cross-Validation")
    print("  ‚ö†Ô∏è  P√©nalit√©s s√©v√®res pour scores parfaits sur petits datasets")
    print("="*80)
    
    # Connexion √† Azure ML
    azure_ml_client = None
    if SUBSCRIPTION_ID and RESOURCE_GROUP and WORKSPACE_NAME:
        try:
            print("\nüîó Connexion √† Azure ML Workspace...")
            # Essayer AzureCliCredential en premier (si az login a √©t√© fait)
            try:
                credential = AzureCliCredential()
                azure_ml_client = MLClient(
                    credential=credential,
                    subscription_id=SUBSCRIPTION_ID,
                    resource_group_name=RESOURCE_GROUP,
                    workspace_name=WORKSPACE_NAME
                )
                print("  ‚úì Connect√© via Azure CLI")
            except:
                # Fallback vers DefaultAzureCredential
                credential = DefaultAzureCredential()
                azure_ml_client = MLClient(
                    credential=credential,
                    subscription_id=SUBSCRIPTION_ID,
                    resource_group_name=RESOURCE_GROUP,
                    workspace_name=WORKSPACE_NAME
                )
                print("  ‚úì Connect√© via DefaultAzureCredential")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Impossible de se connecter √† Azure ML: {e}")
            print("  ‚ÑπÔ∏è  Les mod√®les seront sauvegard√©s localement uniquement")
    else:
        print("\n‚ö†Ô∏è Configuration Azure ML manquante dans .env")
        print("   Les mod√®les seront sauvegard√©s localement uniquement")
    
    # Configurer MLflow pour Azure ML
    if azure_ml_client:
        # Obtenir l'URI de tracking d'Azure ML
        workspace = azure_ml_client.workspaces.get(WORKSPACE_NAME)
        mlflow_tracking_uri = workspace.mlflow_tracking_uri
        mlflow.set_tracking_uri(mlflow_tracking_uri)
        print(f"  ‚úì MLflow tracking URI: {mlflow_tracking_uri}")
    
    # Configurer l'exp√©rience
    experiment_name = "weather-unified-forecast"
    mlflow.set_experiment(experiment_name)
    
    # D√©marrer un run MLflow/Azure ML
    with mlflow.start_run(run_name=f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}") as run:
        
        print(f"\nüî¨ Run ID: {run.info.run_id}")
        
        # Initialiser le pipeline
        pipeline = WeatherMLPipeline(
            storage_account_name=STORAGE_ACCOUNT,
            container_name=CONTAINER,
            storage_account_key=STORAGE_KEY,
            experiment_name=experiment_name,
            azure_ml_client=azure_ml_client
        )
        
        # Charger les donn√©es
        print("\nüìÅ Chargement des donn√©es depuis Azure Blob Storage...")
        df = pipeline.load_data_from_blob("bronze/history")
        
        if df is None or len(df) == 0:
            print("\n‚úó Aucune donn√©e disponible")
            return
        
        # Feature engineering
        print("\nüîß Feature engineering...")
        df_features = pipeline.feature_engineering(df)
        
        # Cr√©er la cible de classification
        df_features = pipeline.create_classification_target(df_features, threshold=0.1)
        
        # ========================================================================
        # PARTIE 1: ENTRA√éNEMENT DES MOD√àLES DE TEMP√âRATURE
        # ========================================================================
        print("\n" + "="*80)
        print("PARTIE 1: MOD√àLES DE TEMP√âRATURE")
        print("="*80)
        
        X_temp, y_temp, feature_names_temp = pipeline.prepare_features_target(
            df_features, target='temp_c'
        )
        
        print(f"\nüìã Donn√©es temp√©rature:")
        print(f"  Features: {len(feature_names_temp)}")
        print(f"  Observations: {len(X_temp)}")
        
        # Split pour temp√©rature
        X_temp_train, X_temp_test, y_temp_train, y_temp_test = train_test_split(
            X_temp, y_temp, test_size=0.2, random_state=42
        )
        
        print(f"  Train: {len(X_temp_train)} | Test: {len(X_temp_test)}")
        
        # Normalisation
        print("\nüîÑ Normalisation...")
        pipeline.scaler.fit(X_temp_train)
        X_temp_train_scaled = pipeline.scaler.transform(X_temp_train)
        X_temp_test_scaled = pipeline.scaler.transform(X_temp_test)
        
        # Entra√Æner les mod√®les de temp√©rature
        temp_results = pipeline.train_temperature_models(
            X_temp_train_scaled, X_temp_test_scaled, y_temp_train, y_temp_test
        )
        
        # ========================================================================
        # PARTIE 2: ENTRA√éNEMENT DES MOD√àLES DE PLUIE (avec temp√©rature)
        # ========================================================================
        print("\n" + "="*80)
        print("PARTIE 2: MOD√àLES DE PLUIE (avec temp√©rature pr√©dite)")
        print("="*80)
        
        # Pr√©parer les donn√©es pour la pluie
        X_rain_base, _, _ = pipeline.prepare_features_target(df_features, target='temp_c')
        y_rain = df_features.loc[X_rain_base.index, 'will_rain']
        
        # Analyser le d√©s√©quilibre
        strategy = pipeline.analyze_data_balance(y_rain, task='classification')
        
        # V√©rifier si on a au moins 2 classes
        n_classes_rain = len(np.unique(y_rain))
        
        rain_results = {}
        
        if n_classes_rain < 2:
            print("\n‚ö†Ô∏è ATTENTION CRITIQUE: Une seule classe dans les donn√©es de pluie!")
            print(f"   Classe pr√©sente: {np.unique(y_rain)}")
            print(f"   Impossible de cr√©er un mod√®le de classification binaire.")
            print(f"\n‚è≠Ô∏è  Passage √† la sauvegarde des r√©sultats de temp√©rature uniquement...")
            
            pipeline.rain_model_available = False
            
            # Afficher uniquement les r√©sultats temp√©rature
            print("\n" + "="*80)
            print("üìä R√âSULTATS - TEMP√âRATURE UNIQUEMENT")
            print("="*80)
            
            temp_df = pd.DataFrame({
                'Model': list(temp_results.keys()),
                'MAE (¬∞C)': [r['mae_test'] for r in temp_results.values()],
                'RMSE (¬∞C)': [r['rmse_test'] for r in temp_results.values()],
                'R¬≤': [r['r2_test'] for r in temp_results.values()]
            })
            temp_df = temp_df.sort_values('R¬≤', ascending=False)
            temp_df['Best'] = temp_df['Model'].apply(
                lambda x: 'üèÜ' if x == pipeline.best_temp_model_name else ''
            )
            print(temp_df.to_string(index=False))
            
            print(f"\nüèÜ MEILLEUR MOD√àLE:")
            print(f"  ‚Ä¢ Temp√©rature: {pipeline.best_temp_model_name} (R¬≤={pipeline.best_temp_score:.3f})")
            
            # Enregistrer dans Azure ML
            pipeline.log_temperature_only_azure(run, feature_names_temp)
            
            print("\n‚úÖ Mod√®le de temp√©rature sauvegard√© avec succ√®s!")
            print("\nüîî NOTE: Le d√©ploiement se fera avec le mod√®le temp√©rature uniquement")
            return
        
        # Si on a au moins 2 classes, continuer avec l'entra√Ænement pluie
        pipeline.rain_model_available = True
        
        # Split pour pluie
        X_rain_base_train, X_rain_base_test, y_rain_train, y_rain_test = train_test_split(
            X_rain_base, y_rain, test_size=0.2, random_state=42, stratify=y_rain
        )
        
        # Normaliser
        X_rain_base_train_scaled = pipeline.scaler.transform(X_rain_base_train)
        X_rain_base_test_scaled = pipeline.scaler.transform(X_rain_base_test)
        
        # AJOUTER la temp√©rature pr√©dite comme feature
        print("\n‚ûï Ajout de la temp√©rature pr√©dite comme feature...")
        temp_pred_train = pipeline.best_temp_model.predict(X_rain_base_train_scaled)
        temp_pred_test = pipeline.best_temp_model.predict(X_rain_base_test_scaled)
        
        X_rain_train = np.column_stack([X_rain_base_train_scaled, temp_pred_train])
        X_rain_test = np.column_stack([X_rain_base_test_scaled, temp_pred_test])
        
        print(f"  ‚úì Features pluie: {X_rain_train.shape[1]} (incluant temp√©rature pr√©dite)")
        
        # Balancing si n√©cessaire
        if strategy != 'none':
            X_rain_train, y_rain_train = pipeline.balance_data(
                X_rain_train, y_rain_train, strategy=strategy
            )
        
        # Entra√Æner les mod√®les de pluie (avec d√©tection overfitting AM√âLIOR√âE)
        rain_results = pipeline.train_rain_models(
            X_rain_train, X_rain_test, y_rain_train, y_rain_test
        )
        
        # ========================================================================
        # PARTIE 3: CR√âER ET ENREGISTRER LE PIPELINE UNIFI√â
        # ========================================================================
        
        # Afficher la comparaison
        temp_df, rain_df = pipeline.display_comparison(temp_results, rain_results)
        
        # Cr√©er le pipeline unifi√©
        if rain_results and pipeline.rain_model_available:
            unified_pipeline = pipeline.create_unified_pipeline()
            
            # Enregistrer dans Azure ML
            feature_names_rain = feature_names_temp + ['temp_predicted']
            pipeline.log_unified_pipeline_azure(
                run, X_temp_train_scaled, feature_names_temp, feature_names_rain
            )
        
        # ========================================================================
        # PARTIE 4: TEST DU PIPELINE UNIFI√â
        # ========================================================================
        if rain_results and pipeline.unified_pipeline:
            print("\n" + "="*80)
            print("üß™ TEST DU PIPELINE UNIFI√â")
            print("="*80)
            
            # Prendre quelques exemples de test
            n_samples = min(5, len(X_temp_test_scaled))
            X_test_sample = X_temp_test_scaled[:n_samples]
            
            print(f"\nüîÆ Pr√©dictions sur {n_samples} exemples:")
            predictions = pipeline.unified_pipeline.predict_proba(X_test_sample)
            
            for i in range(n_samples):
                print(f"\n  Exemple {i+1}:")
                print(f"    Temp√©rature r√©elle: {y_temp_test.iloc[i]:.1f}¬∞C")
                print(f"    Temp√©rature pr√©dite: {predictions['temperature'][i]:.1f}¬∞C")
                print(f"    Pluie r√©elle: {'Oui' if y_rain_test.iloc[i] == 1 else 'Non'}")
                print(f"    Pluie pr√©dite: {'Oui' if predictions['will_rain'][i] == 1 else 'Non'}")
                print(f"    Probabilit√© de pluie: {predictions['rain_probability'][i]:.1%}")
        
        # ========================================================================
        # R√âSUM√â FINAL
        # ========================================================================
        print("\n" + "="*80)
        print("‚úÖ PIPELINE TERMIN√â AVEC SUCC√àS")
        print("="*80)
        
        print(f"\nüìä R√©sultats:")
        print(f"  ‚Ä¢ Mod√®les temp√©rature test√©s: {len(temp_results)}")
        if rain_results:
            print(f"  ‚Ä¢ Mod√®les pluie test√©s: {len(rain_results)}")
        print(f"  ‚Ä¢ Meilleur temp√©rature: {pipeline.best_temp_model_name} (R¬≤={pipeline.best_temp_score:.3f})")
        if pipeline.best_rain_model_name:
            overfitting_note = " ‚ö†Ô∏è (overfitting)" if pipeline.best_rain_metrics.get('overfitting_detected', False) else ""
            print(f"  ‚Ä¢ Meilleur pluie: {pipeline.best_rain_model_name} (Score={pipeline.best_rain_score:.3f}){overfitting_note}")
        
        if azure_ml_client:
            print(f"\n‚òÅÔ∏è  Mod√®les enregistr√©s dans Azure ML:")
            if rain_results and pipeline.rain_model_available:
                print(f"  ‚Ä¢ weather_unified_pipeline")
                print(f"  ‚Ä¢ weather_temperature_{pipeline.best_temp_model_name.lower()}")
                print(f"  ‚Ä¢ weather_rain_{pipeline.best_rain_model_name.lower()}")
            else:
                print(f"  ‚Ä¢ weather_temperature_{pipeline.best_temp_model_name.lower()}")
            
            print(f"\nüéØ Pr√™t pour le d√©ploiement automatique!")
            print(f"  Les mod√®les sont disponibles dans Azure ML Model Registry")
        else:
            print(f"\n‚ö†Ô∏è Mod√®les sauvegard√©s localement uniquement")
            print(f"  Configure Azure ML pour enregistrer dans le cloud")
        
        if pipeline.best_rain_metrics.get('overfitting_detected', False):
            print(f"\n‚ö†Ô∏è  AVERTISSEMENT:")
            print(f"  Le mod√®le de pluie pr√©sente des signes d'overfitting")
            print(f"  Recommandation: Collecter plus de donn√©es avant d√©ploiement production")
        
        print("\n" + "="*80)


if __name__ == "__main__":
    main()